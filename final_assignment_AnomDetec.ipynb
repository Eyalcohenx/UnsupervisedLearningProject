{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cecno1f-iYOH"
      },
      "source": [
        "#Instalments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOZnP6NHid2-",
        "outputId": "ce32dfc3-1fd4-4083-a4ae-8103aa1276ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyod\n",
            "  Downloading pyod-0.9.8.tar.gz (114 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▉                             | 10 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 20 kB 31.5 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 30 kB 37.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 40 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 51 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 61 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 71 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 81 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 92 kB 27.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 102 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 112 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 114 kB 25.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyod) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pyod) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.21.5)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from pyod) (0.51.2)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.4.1)\n",
            "Requirement already satisfied: scikit_learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pyod) (1.15.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod) (0.10.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod) (57.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>=0.20.0->pyod) (3.1.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (0.11.0)\n",
            "Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (1.3.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (0.5.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->statsmodels->pyod) (2018.9)\n",
            "Building wheels for collected packages: pyod\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.9.8-py3-none-any.whl size=136775 sha256=51f9085f3e4e1db7a0e8f977c454674fb3d6bf42e68543d18708f50cbe088dcd\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/8f/95/6cb376aec9fae09d9b1622d1662c902b522deb353cb80836a6\n",
            "Successfully built pyod\n",
            "Installing collected packages: pyod\n",
            "Successfully installed pyod-0.9.8\n"
          ]
        }
      ],
      "source": [
        "!pip install pyod "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih8dOzWtNSnS",
        "outputId": "1fc0df4e-d3cb-4599-ab8c-0bd089e48210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/MaxHalford/prince.git\n",
            "  Cloning https://github.com/MaxHalford/prince.git to /tmp/pip-req-build-8500cwt1\n",
            "  Running command git clone -q https://github.com/MaxHalford/prince.git /tmp/pip-req-build-8500cwt1\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from prince==0.7.0) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.1 in /usr/local/lib/python3.7/dist-packages (from prince==0.7.0) (1.21.5)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from prince==0.7.0) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from prince==0.7.0) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from prince==0.7.0) (1.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->prince==0.7.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->prince==0.7.0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->prince==0.7.0) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.2->prince==0.7.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.3->prince==0.7.0) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.2->prince==0.7.0) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->prince==0.7.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->prince==0.7.0) (1.1.0)\n",
            "Building wheels for collected packages: prince\n",
            "  Building wheel for prince (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prince: filename=prince-0.7.0-py3-none-any.whl size=26169 sha256=9126f980012ed5d10ecb4f4abcb6ffaa9dc388610bb5e605ed2c32fe1d0e93b9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bwi6i5cs/wheels/94/18/66/38480b5bb8b2162a521eaef3e5e88a4090198324fe65f3a152\n",
            "Successfully built prince\n",
            "Installing collected packages: prince\n",
            "Successfully installed prince-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/MaxHalford/prince.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckm71lWniWjF",
        "outputId": "d9fd7b0f-9a80-44c2-c754-b633539dcf99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hdbscan\n",
            "  Downloading hdbscan-0.8.28.tar.gz (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 25.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (0.29.28)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.0.2)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->hdbscan) (3.1.0)\n",
            "Building wheels for collected packages: hdbscan\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.28-cp37-cp37m-linux_x86_64.whl size=2330804 sha256=371c8adf9e49c97ac68da2e882413f83edef27e59441bf8177cd7eb624dcc3a9\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/7a/5e/259ccc841c085fc41b99ef4a71e896b62f5161f2bc8a14c97a\n",
            "Successfully built hdbscan\n",
            "Installing collected packages: hdbscan\n",
            "Successfully installed hdbscan-0.8.28\n"
          ]
        }
      ],
      "source": [
        "!pip install hdbscan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eo17Vspokkbo"
      },
      "outputs": [],
      "source": [
        "# !pip install shap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU5BxJuskqoT"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPEEF2TCw4kw"
      },
      "outputs": [],
      "source": [
        "from os import path, system\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import seaborn as sns\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "\n",
        "# Scipy\n",
        "import scipy\n",
        "from scipy.stats import f_oneway\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.csgraph import dijkstra\n",
        "\n",
        "\n",
        "# sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn.manifold import LocallyLinearEmbedding\n",
        "from sklearn.manifold import MDS\n",
        "from sklearn.manifold import Isomap\n",
        "from sklearn.manifold import SpectralEmbedding\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.metrics import mutual_info_score, normalized_mutual_info_score\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.neighbors import radius_neighbors_graph\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "\n",
        "# PyOD\n",
        "from pyod.models.copod import COPOD\n",
        "from pyod.models.hbos import HBOS\n",
        "from pyod.models.sos import SOS\n",
        "from pyod.models.abod import ABOD\n",
        "from pyod.models.lmdd import LMDD\n",
        "from pyod.models.ocsvm import OCSVM\n",
        "from pyod.models.auto_encoder import AutoEncoder\n",
        "from pyod.models.deep_svdd import DeepSVDD\n",
        "from pyod.models.cof import COF\n",
        "from pyod.models.pca import PCA\n",
        "from pyod.models.knn import KNN\n",
        "from pyod.models.iforest import IForest\n",
        "\n",
        "\n",
        "# matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.ticker import NullFormatter\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.cm as cm\n",
        "%matplotlib inline\n",
        "\n",
        "# Timing\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# HDBSCAN\n",
        "from hdbscan import HDBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "323pQR5a3dbB"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "PHp6BMPDfmeK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVBXP-IDu2g0"
      },
      "outputs": [],
      "source": [
        "def load_dataset(dataset_path, one_in_every, sample=False):\n",
        "\n",
        "    if not path.exists(dataset_path):\n",
        "        system('cat data/USCensus1990.data.txt.* > data/USCensus1990.data.txt')\n",
        "\n",
        "    if sample:\n",
        "      a_dataframe = pd.read_csv(dataset_path, header=0, skiprows=lambda i: i % one_in_every != 0)\n",
        "    else:\n",
        "      a_dataframe = pd.read_csv(dataset_path)\n",
        "\n",
        "\n",
        "    # need to ignore caseid\n",
        "    a_dataframe = a_dataframe.drop(columns=['caseid'])\n",
        "\n",
        "    return a_dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8NezaW_1K-T"
      },
      "outputs": [],
      "source": [
        "def OutlierFilter(X_train, alg=0, outlier_frac=0.1):\n",
        "  \n",
        "    # Proximity-Based - Connectivity-Based Outlier Factor\n",
        "    if alg == 0 or alg == 'pca' or alg == 'PCA':\n",
        "        clf = PCA()\n",
        "\n",
        "    # Linear Model - One-Class Support Vector Machines\n",
        "    elif alg == 1 or alg == 'knn' or alg == 'KNN':\n",
        "        clf = KNN(contamination=0.1, n_neighbors=5, method='median', radius=1.0,\n",
        "                  algorithm='auto', leaf_size=30, metric='minkowski', p=2, \n",
        "                  metric_params=None, n_jobs=1)\n",
        "\n",
        "    # AutoEncoder\n",
        "    elif alg == 2 or alg == 'auto_encoder' or alg == 'AutoEncoder':\n",
        "        clf = AutoEncoder(epochs=100, batch_size=32, dropout_rate=0.2, \n",
        "                          l2_regularizer=0.1, validation_size=0.1, \n",
        "                          preprocessing=True, verbose=1, random_state=None, \n",
        "                          contamination=outlier_frac)\n",
        "\n",
        "    # Neural Network - Deep One-Class Classification\n",
        "    elif alg == 3 or alg == 'DeepSVDD':\n",
        "        clf = DeepSVDD(c=None, use_ae=True, hidden_neurons=None, \n",
        "                       hidden_activation='relu', output_activation='sigmoid', \n",
        "                       optimizer='adam', epochs=30, batch_size=32, \n",
        "                       dropout_rate=0.2, l2_regularizer=0.1, \n",
        "                       validation_size=0.1, preprocessing=True, verbose=1, \n",
        "                       random_state=None, contamination=outlier_frac)\n",
        "        \n",
        "    # Neural Network - Deep One-Class Classification\n",
        "    elif alg == 4 or alg == 'iforest':\n",
        "        clf = IForest(contamination=outlier_frac)\n",
        "\n",
        "    else:\n",
        "        print(\"Unknown outliers screening algorithm\")\n",
        "\n",
        "    X_train = X_train.astype(float)\n",
        "    clf.fit(X_train)\n",
        "\n",
        "    # y_pred = clf.predict(X_train[feat_cols].values)  # predict outliers\n",
        "    # outlier_index = np.where(y_pred == 1)\n",
        "\n",
        "    return clf  # outlier_index[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1Tb75ZuNnbT"
      },
      "outputs": [],
      "source": [
        "def Clustering(X, alg=0, n_clusters=10):\n",
        "  \n",
        "    # K-means  - To Do: try to import and use fuzzy kmean\n",
        "    if alg == 0 or alg == 'kmeans' or alg == 'KMEANS':\n",
        "        clusterer = KMeans(n_clusters=n_clusters)\n",
        "\n",
        "    # AgglomerativeClustering\n",
        "    elif alg == 1 or alg == 'agg' or alg == 'AgglomerativeClustering':\n",
        "        clusterer = AgglomerativeClustering(n_clusters=n_clusters)\n",
        "\n",
        "    # DBSCAN\n",
        "    elif alg == 2 or alg == 'dbscan' or alg == 'DBSCAN':\n",
        "        clusterer = DBSCAN(eps=0.1, min_samples=50)\n",
        "\n",
        "    # HDBSCAN - To Do: import and use hdbscan\n",
        "    elif alg == 3 or alg == 'hdbscan' or alg == 'HDBSCAN':\n",
        "        clusterer = HDBSCAN(cluster_selection_epsilon=0.3, min_cluster_size=200, \n",
        "                            min_samples=5)\n",
        "    \n",
        "    else:\n",
        "        print(\"Unknown algorithm\")\n",
        "\n",
        "    result = clusterer.fit(X)\n",
        "    return result  # .labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5U92NJdsZGC"
      },
      "outputs": [],
      "source": [
        "def DimensionReduction(X, alg=0, neighbors_num=10):\n",
        "  \n",
        "    # PCA\n",
        "    if alg == 0 or alg == 'pca' or alg == 'PCA':\n",
        "        dim_reductor = PCA(n_components=10)\n",
        "\n",
        "    # MDS\n",
        "    elif alg == 1 or alg == 'mds' or alg == 'MDS':\n",
        "        dim_reductor = MDS(n_components = 2, max_iter=100, n_init=1)\n",
        "\n",
        "    # LLE - LocallyLinearEmbedding\n",
        "    elif alg == 2 or alg == 'lle' or alg == 'LLE':\n",
        "        dim_reductor = LocallyLinearEmbedding(n_neighbors=neighbors_num, \n",
        "                                              n_components=2, \n",
        "                                              eigen_solver='auto', \n",
        "                                              method='standard')\n",
        "\n",
        "    # LEM (Laplacian Eigenmaps)\n",
        "    elif alg == 3 or alg == 'lem' or alg == 'LEM':\n",
        "        dim_reductor = SpectralEmbedding(n_neighbors=neighbors_num, \n",
        "                                         n_components=2)\n",
        "        \n",
        "    # Isomap\n",
        "    elif alg == 5 or alg == 'isomap' or alg == 'ISOMAP':\n",
        "        dim_reductor = Isomap(n_neighbors=neighbors_num, n_components=2)\n",
        "\n",
        "    # ICA\n",
        "    elif alg == 6 or alg == 'ica' or alg == 'ICA':\n",
        "        dim_reductor = FastICA(n_components = 2)\n",
        "\n",
        "    # t-SNE\n",
        "    elif alg == 7 or alg == 'tsne' or alg == 'TSNE':\n",
        "        dim_reductor = TSNE(n_components = 2)\n",
        "\n",
        "    # KNN Graph\n",
        "    elif alg == 8 or alg == 'tsne' or alg == 'TSNE':\n",
        "        knn_graph = kneighbors_graph(X, n_neighbors=neighbors_num, \n",
        "                                     mode='connectivity', include_self=True)\n",
        "        radius_knn_graph = radius_neighbors_graph(knn_graph, radius=3, \n",
        "                                                  mode='connectivity', \n",
        "                                                  include_self=True)\n",
        "        dist_matrix, predecessors = dijkstra(csgraph=radius_knn_graph, \n",
        "                                             directed=False, \n",
        "                                             return_predecessors=True)\n",
        "\n",
        "        dim_reductor = MDS(n_components=2)\n",
        "        return dim_reductor.fit_transform(df[feat_cols].values)\n",
        "    \n",
        "    else:\n",
        "        print(\"Unknown algorithm\")\n",
        "\n",
        "    return dim_reductor.fit_transform(df[feat_cols].values)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "S_qILe2XfqOi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bknoiVsgGGfO"
      },
      "outputs": [],
      "source": [
        "# https://towardsdatascience.com/silhouette-coefficient-validating-clustering-techniques-e976bb81d10c\n",
        "\n",
        "# https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
        "\n",
        "def silhouette_graph(X_sample, labels, n_clusters, silhouette_avg):\n",
        "    sample_silhouette_values = silhouette_samples(X_sample, labels)\n",
        "\n",
        "    fig, ax1 = plt.subplots()\n",
        "    fig.set_size_inches(7, 7)\n",
        "    \n",
        "    y_lower = 10\n",
        "\n",
        "    for i in range(n_clusters):\n",
        "        ith_cluster_silhouette_values = sample_silhouette_values[labels == i]\n",
        "\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "        ax1.fill_betweenx(\n",
        "            np.arange(y_lower, y_upper),\n",
        "            0,\n",
        "            ith_cluster_silhouette_values,\n",
        "            facecolor=color,\n",
        "            edgecolor=color,\n",
        "            alpha=0.7,\n",
        "        )\n",
        "        \n",
        "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "        y_lower = y_upper + 10\n",
        "\n",
        "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
        "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
        "    ax1.set_ylabel(\"Cluster label\")\n",
        "\n",
        "    # The vertical line for average silhouette score of all the values\n",
        "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "    \n",
        "    ax1.set_yticks([])\n",
        "    ax1.set_xticks([-0.4,-0.2,-0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "    print(\"save fig\")\n",
        "    images_dir = '/content/drive/MyDrive/Unsupervised-Learning/Final-Project/'\n",
        "    fig.savefig(f\"{images_dir}/tryout.svg\")\n",
        "    # fig.savefig('tryout', format='svg', dpi=1200)\n",
        "    \n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fy2zGoablF7k"
      },
      "outputs": [],
      "source": [
        "def run_experiment(X_train, y_train, n_experiments, sample_frac,\n",
        "                   AD_model, outlier_frac, Cluster_models, n_clusters):\n",
        "    print(\"Preprocessing starts\")\n",
        "    start = timer()\n",
        "    mi_scores = {}\n",
        "    silhouette_scores = {}\n",
        "    for Cluster_model in Cluster_models:\n",
        "      mi_scores[Cluster_model] = {}\n",
        "      silhouette_scores[Cluster_model] = []\n",
        "      for variable in label_col:\n",
        "        mi_scores[Cluster_model][variable] = []\n",
        "\n",
        "    filtered_data = X_train\n",
        "    filtered_labels = y_train\n",
        "    \n",
        "    end = timer()\n",
        "    print(\"Finished preprocessing, preprocessing time was \" + str(end - start) + \" seconds\\n\")\n",
        "    \n",
        "    for exp in range(n_experiments):\n",
        "        start = timer()\n",
        "        print(\"starting experiment number \" + str(exp))\n",
        "        \n",
        "        # Use train_test_split to split x and y correspondingly\n",
        "        _, X_sample, _, y_sample = train_test_split(filtered_data, filtered_labels, \n",
        "                                                    test_size=sample_frac)\n",
        "        X_sample.reset_index(drop=True, inplace=True)\n",
        "        y_sample.reset_index(drop=True, inplace=True)\n",
        "        \n",
        "        # Cluster methods\n",
        "        for Cluster_model in Cluster_models:\n",
        "          clusterer = Clustering(X_sample, alg=Cluster_model, \n",
        "                                 n_clusters=n_clusters)\n",
        "          clusters_labels = clusterer.labels_\n",
        "          cluster_num = len(np.unique(clusters_labels, return_counts=False))\n",
        "\n",
        "          # mutual_info_score\n",
        "          for variable in label_col:\n",
        "            # Mutual information\n",
        "            mi_variable = normalized_mutual_info_score(y_sample[variable].to_numpy(), clusters_labels)\n",
        "            mi_scores[Cluster_model][variable].append(mi_variable)\n",
        "            \n",
        "          # Silhouette\n",
        "          silhouette_avg = silhouette_score(X_sample, clusters_labels)\n",
        "          silhouette_scores[Cluster_model].append(silhouette_avg)\n",
        "          \n",
        "          # silhouette_graph(X_sample, clusters_labels, cluster_num, silhouette_avg)\n",
        "        \n",
        "        end = timer()\n",
        "        print(\"Finished experiment number \" + str(exp) + \", time was \" + str(end - start) + \" seconds\\n\")\n",
        "\n",
        "\n",
        "    return mi_scores, silhouette_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyG_V-mVwJPy"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wddPeaEy1S3Y",
        "outputId": "45e46ad1-7669-4704-c739-5709c7fb3543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-rV_d33VnzK",
        "outputId": "bd0d1cd0-2b01-492e-d1d7-96da89325e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UnsupervisedLearningProject'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/21)\u001b[K\rremote: Counting objects:   9% (2/21)\u001b[K\rremote: Counting objects:  14% (3/21)\u001b[K\rremote: Counting objects:  19% (4/21)\u001b[K\rremote: Counting objects:  23% (5/21)\u001b[K\rremote: Counting objects:  28% (6/21)\u001b[K\rremote: Counting objects:  33% (7/21)\u001b[K\rremote: Counting objects:  38% (8/21)\u001b[K\rremote: Counting objects:  42% (9/21)\u001b[K\rremote: Counting objects:  47% (10/21)\u001b[K\rremote: Counting objects:  52% (11/21)\u001b[K\rremote: Counting objects:  57% (12/21)\u001b[K\rremote: Counting objects:  61% (13/21)\u001b[K\rremote: Counting objects:  66% (14/21)\u001b[K\rremote: Counting objects:  71% (15/21)\u001b[K\rremote: Counting objects:  76% (16/21)\u001b[K\rremote: Counting objects:  80% (17/21)\u001b[K\rremote: Counting objects:  85% (18/21)\u001b[K\rremote: Counting objects:  90% (19/21)\u001b[K\rremote: Counting objects:  95% (20/21)\u001b[K\rremote: Counting objects: 100% (21/21)\u001b[K\rremote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 21 (delta 6), reused 17 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n",
            "Checking out files: 100% (10/10), done.\n",
            "/content/UnsupervisedLearningProject\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Eyalcohenx/UnsupervisedLearningProject\n",
        "%cd /content/UnsupervisedLearningProject"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGdEg8SL0YBw"
      },
      "source": [
        "##Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9v2eHxc0aQz"
      },
      "outputs": [],
      "source": [
        "# Loading the data\n",
        "data = load_dataset('data/USCensus1990.data.txt', one_in_every=10, sample=True)\n",
        "print(len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9n1fcry5b7h"
      },
      "outputs": [],
      "source": [
        "label_col = ['dAge', 'dHispanic', 'iYearwrk', 'iSex']\n",
        "all_col = data.columns.values.tolist()\n",
        "feat_cols = list(set(all_col) - set(label_col))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veOVBjC6ldPJ",
        "outputId": "d958a0de-2d73-4fa1-9e9f-0c0c42686dbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dIncome2', 'dIncome8', 'dIncome3', 'iMay75880', 'iRrelchld', 'iFeb55', 'iWWII', 'dIncome7', 'iSept80', 'dIncome5', 'dIncome6', 'iVietnam', 'iKorean', 'iOthrserv', 'dIncome4', 'iRownchld']\n",
            "16\n"
          ]
        }
      ],
      "source": [
        "bin_col = data.columns[data.isin([0,1]).all()]\n",
        "bin_feat_col = list(set(bin_col) - set(label_col))\n",
        "non_bin_feat_col = list(set(feat_cols) - set(bin_feat_col))\n",
        "\n",
        "print(bin_feat_col)\n",
        "print(len(bin_feat_col))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSsFJvpOCvuW"
      },
      "source": [
        "## One-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsVDut1178xT"
      },
      "outputs": [],
      "source": [
        "enc_X = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "\n",
        "one_hot_data_X = enc_X.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2k2oD-17i_Sa"
      },
      "outputs": [],
      "source": [
        "X_train = one_hot_data_X\n",
        "y_train = data[label_col]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS9onhy1h2pz"
      },
      "source": [
        "## MCA of discrete features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kccGhIbpOypc"
      },
      "source": [
        "Some of the data is categorical, so encode to one hot, do an MCA (which is a PCA to one hot) and then run all the methods into a cluster, and so on. Record in the file whether we treated the data as categorical or not.\n",
        "\n",
        "Run MCA on the discrete variables and PCA on the continuous variables and then connect everything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xR7ui-x0aNz"
      },
      "outputs": [],
      "source": [
        "# https://github.com/MaxHalford/prince\n",
        "from prince import MCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6g-CMh7yny4K"
      },
      "outputs": [],
      "source": [
        "mca = MCA(\n",
        "    n_components=50,\n",
        "    n_iter=3,\n",
        "    copy=True,\n",
        "    check_input=True,\n",
        "    engine='auto',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "mca_transformed_train_data = mca.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWT_sRFww4UT"
      },
      "outputs": [],
      "source": [
        "# mca_transformed_test_data = mca.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jgGAMPMGwZF"
      },
      "outputs": [],
      "source": [
        "# mca.column_contributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_apT5pm-lU2"
      },
      "outputs": [],
      "source": [
        "# type(mca_transformed_train_data)\n",
        "# print(mca_transformed_train_data.columns.values.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anomaly Detection"
      ],
      "metadata": {
        "id": "XuDGSK8Me-2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outlier_filter = OutlierFilter(mca_transformed_train_data, alg='iforest', \n",
        "                               outlier_frac=0.005)"
      ],
      "metadata": {
        "id": "ohVvFs1nfLl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_anom_pred = outlier_filter.predict(mca_transformed_train_data.values)  # predict outliers\n",
        "train_outlier_index = np.where(train_anom_pred == 1)[0]"
      ],
      "metadata": {
        "id": "yYCZMo5UfHWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outlier_data = data.iloc[train_outlier_index]"
      ],
      "metadata": {
        "id": "GQulAYBBfFbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outlier_data_external = outlier_data[label_col]"
      ],
      "metadata": {
        "id": "boxJnxnMhbWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outlier_data_external.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "S7X5lBXfh-Gh",
        "outputId": "62d396bf-812e-4f5e-8bf4-7361bb4ec393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              dAge    dHispanic     iYearwrk         iSex\n",
              "count  1230.000000  1230.000000  1230.000000  1230.000000\n",
              "mean      4.665854     0.417886     2.905691     0.408943\n",
              "std       1.558636     1.502698     2.158688     0.491839\n",
              "min       0.000000     0.000000     0.000000     0.000000\n",
              "25%       3.000000     0.000000     1.000000     0.000000\n",
              "50%       5.000000     0.000000     2.000000     0.000000\n",
              "75%       6.000000     0.000000     5.000000     1.000000\n",
              "max       7.000000     9.000000     7.000000     1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef77d1c5-4308-4c95-91dc-2ebee35660d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dAge</th>\n",
              "      <th>dHispanic</th>\n",
              "      <th>iYearwrk</th>\n",
              "      <th>iSex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1230.000000</td>\n",
              "      <td>1230.000000</td>\n",
              "      <td>1230.000000</td>\n",
              "      <td>1230.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.665854</td>\n",
              "      <td>0.417886</td>\n",
              "      <td>2.905691</td>\n",
              "      <td>0.408943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.558636</td>\n",
              "      <td>1.502698</td>\n",
              "      <td>2.158688</td>\n",
              "      <td>0.491839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef77d1c5-4308-4c95-91dc-2ebee35660d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef77d1c5-4308-4c95-91dc-2ebee35660d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef77d1c5-4308-4c95-91dc-2ebee35660d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOmPA9u1jFUQ"
      },
      "source": [
        "## Evaluation Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KLRmyO7LVdu"
      },
      "source": [
        "**Mutual Information Score:**\n",
        "\n",
        "If you know about a true division of data into labels, (not all external variables are like that) then the mutual information between the clusters that came out and the tagging of the points (according to the external variable) can be a measure of how close they are (the higher the mutual information then the labels increased our certainty and confirm the division into clusters)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGTxLmjSeVHB"
      },
      "outputs": [],
      "source": [
        "mi_scores1, silhouette_scores1 = run_experiment(mca_transformed_train_data, y_train, \n",
        "                                                n_experiments=20, sample_frac=0.1,\n",
        "                                                AD_model='PCA', outlier_frac=0.01,\n",
        "                                                Cluster_models=['kmeans','agg','hdbscan'], \n",
        "                                                n_clusters=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E0iNzDk6kNA"
      },
      "outputs": [],
      "source": [
        "mi_scores1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_scores1"
      ],
      "metadata": {
        "id": "Diw108szqPDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHXc55yRKWAh"
      },
      "source": [
        "**ANOVA (+ t-Test)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEQ6SjUf7Gt9",
        "outputId": "bca39ebf-3a7f-417f-9f33-d05348e97f11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.012559219313851e-17\n"
          ]
        }
      ],
      "source": [
        "F_anova, p_anova = f_oneway(mi_scores1['agg']['iYearwrk'], \n",
        "                            mi_scores1['kmeans']['iYearwrk'],\n",
        "                            mi_scores1['hdbscan']['iYearwrk'])\n",
        "# print(F_anova)\n",
        "print(p_anova)  # need to be less than 0.001 to try t-Test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F_anova, p_anova = f_oneway(mi_scores1['agg']['dAge'], \n",
        "                            mi_scores1['kmeans']['dAge'],\n",
        "                            mi_scores1['hdbscan']['dAge'])\n",
        "# print(F_anova)\n",
        "print(p_anova)  # need to be less than 0.001 to try t-Test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUWtP8-N6NCK",
        "outputId": "f643c4f7-c9df-4ce6-98bc-1d2167320572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.549468400556941e-23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F_anova, p_anova = f_oneway(mi_scores1['agg']['iSex'], \n",
        "                            mi_scores1['kmeans']['iSex'],\n",
        "                            mi_scores1['hdbscan']['iSex'])\n",
        "# print(F_anova)\n",
        "print(p_anova)  # need to be less than 0.001 to try t-Test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTntktDn6SZa",
        "outputId": "0e097554-852c-4e5a-e223-3861b10a87fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5294273607874593e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F_anova, p_anova = f_oneway(mi_scores1['agg']['dHispanic'], \n",
        "                            mi_scores1['kmeans']['dHispanic'],\n",
        "                            mi_scores1['hdbscan']['dHispanic'])\n",
        "# print(F_anova)\n",
        "print(p_anova)  # need to be less than 0.001 to try t-Test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ022KSU6ctc",
        "outputId": "03f58e58-69a3-4727-8f69-11c2cc08065e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.40516801497075927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doZDRFoeNCkp",
        "outputId": "6fbcab61-4f9c-400f-ee4f-9927c219d598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.298501191338044e-10\n"
          ]
        }
      ],
      "source": [
        "F_ttest,p_ttest = ttest_ind(mi_scores1['agg']['iYearwrk'], \n",
        "                            mi_scores1['hdbscan']['iYearwrk'])\n",
        "\n",
        "# print(F_ttest)\n",
        "print(p_ttest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qWYW1i2M5J5"
      },
      "source": [
        "**Silhouette**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVEsJqFBlWRx"
      },
      "outputs": [],
      "source": [
        "# To do - add silhouette\n",
        "# kmeans_silhouette = silhouette(KMeans, mca_transformed_train_datas)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Cecno1f-iYOH",
        "ZU5BxJuskqoT",
        "323pQR5a3dbB",
        "qdwF0CCbi1if",
        "AS9onhy1h2pz",
        "2gRqRa4v06NE"
      ],
      "name": "final-assignment-Noam",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}